{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "#importing textblob\n",
    "import nltk\n",
    "nltk.download()\n",
    "from textblob import Textblob\n",
    "\n",
    "#specify delimited of csv filed to be the tab character - '\\t\\'\n",
    "#csv file contains no headers so set header = None\n",
    "df = pd.read_csv('Movie_reviews.csv', delimiter = '\\t', header = None)\n",
    "\n",
    "#Creating the sentiment analysis function which returns a sentiment Classification label(1 = positive 0 = negative)\n",
    "def sentimentAnalysis(text):\n",
    "    #calling textblob for the current review\n",
    "    #using exception handler to catch exceptions where the review is not in the proper format\n",
    "    try:\n",
    "        blob = TextBlob(text)\n",
    "    except:\n",
    "        None\n",
    "        return\n",
    "    \n",
    "    sentenceCounter = 0\n",
    "    totalSentiment = 0\n",
    "    print('--New review--')\n",
    "    print('--------------')\n",
    "    #for each review, iterate through the sentences and get the sentiment score of each one\n",
    "    for sentence in blob.sentences:\n",
    "        #the sentenceCounter and totalSentiment will be used to average the sentiment score between \n",
    "        #all the sentences\n",
    "        sentenceCounter = sentenceCounter + 1\n",
    "        totalSentiment = totalSentiment + sentence.sentiment.polarity\n",
    "        #printing each individual sentence and its score given by TextBlob\n",
    "        print(sentence, ' ', sentence.sentiment.polarity)\n",
    "    \n",
    "    #Calculating the average score for the review by dividing the total sentiment\n",
    "    #that was added from each sentence by the number of sentences\n",
    "    averageScore = totalSentiment / sentenceCounter\n",
    "    #printing the average score of the review\n",
    "    print('Average score:', averageScore)\n",
    "    \n",
    "\n",
    "\n",
    "    #returns the average score rounded to 3 decimal places   \n",
    "    return round(averageScore,3)\n",
    "\n",
    "\n",
    "#assigning the actual reviews (third column) into a separate variable\n",
    "movie_reviews = df[2]\n",
    "\n",
    "#creating arrays to store the scores and labels for each review\n",
    "sentimentScores =[]\n",
    "sentimentLabels = []\n",
    "\n",
    "\n",
    "#looping the reviews and for each one, execute the sentimentAnalysis function and create labels for each review\n",
    "#finally store both scores and labels into the respective arrays, these will be appended to the dataframe\n",
    "for index, review_text in enumerate(movie_reviews):\n",
    "    score = sentimentAnalysis(review_text)\n",
    "    try:\n",
    "        if score > 0.1:\n",
    "            sentimentLabels.append('Positive')\n",
    "        else:\n",
    "            sentimentLabels.append('Negative')\n",
    "    except:\n",
    "        sentimentLabels.append('None')\n",
    "            \n",
    "    sentimentScores.append(score)\n",
    "    \n",
    "#After all the reviews have been classified we can append the sentiment Labels and scores into the df\n",
    "df['Sentiment_Scores'] = sentimentScores\n",
    "df['Sentiment_Classification_Labels'] = sentimentLabels\n",
    "\n",
    "#getting a count for both positive and negative reviews\n",
    "positiveCount = len(df[df.Sentiment_Classification_Labels == 'Positive'])\n",
    "negativeCount = len(df[df.Sentiment_Classification_Labels == 'Negative'])\n",
    "\n",
    "#printing the total amount of positive and negative reviews\n",
    "print('')\n",
    "print('--Results--')\n",
    "print('Number of Positive Reviews: ', positiveCount)\n",
    "print('Number of Negative Reviews: ', negativeCount)\n",
    "\n",
    "#display the dataframe which contains all the original columns plus the ones added for the scores and labels\n",
    "#df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "#importing textblob\n",
    "from textblob import TextBlob\n",
    "\n",
    "#specify delimited of csv filed to be the tab character - '\\t\\'\n",
    "#csv file contains no headers so set header = None\n",
    "df = pd.read_csv('Movie_reviews.csv', delimiter = '\\t', header = None)\n",
    "\n",
    "#Creating the sentiment analysis function which returns a sentiment Classification label(1 = positive 0 = negative)\n",
    "def sentimentAnalysis(text):\n",
    "    #calling textblob for the current review\n",
    "    #using exception handler to catch exceptions where the review is not in the proper format\n",
    "    try:\n",
    "        blob = TextBlob(text)\n",
    "    except:\n",
    "        None\n",
    "        return\n",
    "    \n",
    "    sentenceCounter = 0\n",
    "    totalSentiment = 0\n",
    "\n",
    "    #for each review, iterate through the sentences and get the sentiment score of each one\n",
    "    for sentence in blob.sentences:\n",
    "        #the sentenceCounter and totalSentiment will be used to average the sentiment score between \n",
    "        #all the sentences\n",
    "        sentenceCounter = sentenceCounter + 1\n",
    "        totalSentiment = totalSentiment + sentence.sentiment.polarity\n",
    "        \n",
    "    averageScore = totalSentiment / sentenceCounter\n",
    "    #displaying results of the review \n",
    "    #print('Total Sentences:', sentenceCounter, 'Total Sentiment Score', totalSentiment,)\n",
    "    #print('Average Score:', averageScore)\n",
    "\n",
    "\n",
    "    #returns the average score rounded to 3 decimal places   \n",
    "    return round(averageScore,3)\n",
    "\n",
    "\n",
    "#assigning the actual reviews (third column) into a separate variable\n",
    "movie_reviews = df[2]\n",
    "\n",
    "#creating arrays to store the scores and labels for each review\n",
    "sentimentScores =[]\n",
    "sentimentLabels = []\n",
    "\n",
    "\n",
    "#looping the reviews and for each one, execute the sentimentAnalysis function and create labels for each review\n",
    "#finally store both scores and labels into the respective arrays, these will be appended to the dataframe\n",
    "for index, review_text in enumerate(movie_reviews):\n",
    "    score = sentimentAnalysis(review_text)\n",
    "    try:\n",
    "        if score > 0.1:\n",
    "            sentimentLabels.append('Positive')\n",
    "        else:\n",
    "            sentimentLabels.append('Negative')\n",
    "    except:\n",
    "        sentimentLabels.append('None')\n",
    "            \n",
    "    sentimentScores.append(score)\n",
    "    \n",
    "#After all the reviews have been classified we can append the sentiment Labels and scores into the df\n",
    "df['Sentiment_Scores'] = sentimentScores\n",
    "df['Sentiment_Classification_Labels'] = sentimentLabels\n",
    "\n",
    "#getting a count for both positive and negative reviews\n",
    "positiveCount = len(df[df.Sentiment_Classification_Labels == 'Positive'])\n",
    "negativeCount = len(df[df.Sentiment_Classification_Labels == 'Negative'])\n",
    "\n",
    "#drawing a boxplot chart to represent the average sentiment counts\n",
    "df.boxplot(column='Sentiment_Scores', by='Sentiment_Classification_Labels')\n",
    "plt.ylabel(\"Average Sentiment Amount\")\n",
    "plt.xlabel(\"Type of Sentiment\")\n",
    "\n",
    "#using pandas to draw the dataframe based on + and - counts. Declared the x, y and title \n",
    "dfDraw = pd.DataFrame({'Positive': positiveCount, 'Negative': negativeCount}, \n",
    "                  index= {'Positive and Negative movie reviews'})\n",
    "#drawing the dataframe onto a specified barchar\n",
    "ax = dfDraw.plot(kind='bar', title =\"Sentiment Analysis on Movie Reviews\", figsize=(7, 6), legend=True, fontsize=12, rot=0)\n",
    "ax.set_ylabel(\"Number of Reviews\", fontsize=12)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Reviews Bigrams - Sorted By Frequency With No POS Filtering\n",
      "('This', 'is') 400\n",
      "('of', 'the') 371\n",
      "('is', 'a') 370\n",
      "('this', 'movie') 336\n",
      "('one', 'of') 196\n",
      "('I', 'have') 174\n",
      "('I', 'was') 141\n",
      "('This', 'movie') 136\n",
      "('a', 'great') 132\n",
      "('is', 'the') 129\n",
      "('the', 'best') 127\n",
      "('I', 'love') 113\n",
      "('is', 'one') 113\n",
      "('this', 'film') 107\n",
      "('movie', 'is') 105\n",
      "('in', 'the') 101\n",
      "('I', 'am') 87\n",
      "('was', 'a') 86\n",
      "('this', 'is') 85\n",
      "('If', 'you') 84\n",
      "('and', 'I') 79\n",
      "('I', 'had') 75\n",
      "('is', 'an') 70\n",
      "('I', 'saw') 69\n",
      "('of', 'my') 63\n",
      "('saw', 'this') 61\n",
      "('to', 'be') 60\n",
      "('as', 'a') 60\n",
      "('of', 'this') 59\n",
      "('the', 'first') 58\n",
      "('for', 'the') 58\n",
      "('This', 'was') 57\n",
      "('It', 'is') 54\n",
      "('I', 'really') 53\n",
      "('movie', 'was') 53\n",
      "('version', 'of') 52\n",
      "('that', 'I') 51\n",
      "('the', 'original') 51\n",
      "('love', 'this') 50\n",
      "('movie', 'I') 50\n",
      "Negative Reviews Bigrams - Sorted By Frequency With No POS Filtering\n",
      "('this', 'movie') 370\n",
      "('of', 'the') 294\n",
      "('is', 'a') 243\n",
      "('This', 'is') 228\n",
      "('This', 'movie') 209\n",
      "('movie', 'is') 146\n",
      "('this', 'film') 131\n",
      "('one', 'of') 129\n",
      "('I', 'was') 118\n",
      "('I', 'have') 117\n",
      "('was', 'a') 83\n",
      "('movie', 'was') 82\n",
      "('the', 'worst') 81\n",
      "('is', 'one') 80\n",
      "('to', 'be') 79\n",
      "('I', 'am') 77\n",
      "('is', 'the') 74\n",
      "('in', 'the') 73\n",
      "('this', 'is') 72\n",
      "('of', 'this') 71\n",
      "('This', 'film') 70\n",
      "('If', 'you') 66\n",
      "('movie', 'I') 63\n",
      "('I', 'saw') 60\n",
      "('it', 'was') 55\n",
      "('the', 'first') 55\n",
      "('I', 'did') 54\n",
      "('saw', 'this') 54\n",
      "('of', 'a') 53\n",
      "('the', 'movie') 52\n",
      "('film', 'is') 51\n",
      "('and', 'I') 50\n",
      "('I', 'do') 49\n",
      "('I', 'love') 49\n",
      "('a', 'movie') 48\n",
      "('about', 'this') 47\n",
      "('on', 'the') 45\n",
      "('to', 'see') 45\n",
      "('but', 'I') 45\n",
      "('I', 'bought') 44\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk import bigrams\n",
    "from nltk import pos_tag\n",
    "import pandas as pd\n",
    "import operator\n",
    "\n",
    "#importing textblob\n",
    "from textblob import TextBlob\n",
    "\n",
    "#specify delimited of csv filed to be the tab character - '\\t\\'\n",
    "#csv file contains no headers so set header = None\n",
    "df = pd.read_csv('Movie_reviews.csv', delimiter = '\\t', header = None)\n",
    "\n",
    "#Creating the sentiment analysis function which returns a sentiment Classification label(1 = positive 0 = negative)\n",
    "def sentimentAnalysis(text):\n",
    "    #calling textblob for the current review\n",
    "    #using exception handler to catch exceptions where the review is not in the proper format\n",
    "    try:\n",
    "        blob = TextBlob(text)\n",
    "    except:\n",
    "        None\n",
    "        return\n",
    "    \n",
    "    sentenceCounter = 0\n",
    "    totalSentiment = 0\n",
    "\n",
    "    #for each review, iterate through the sentences and get the sentiment score of each one\n",
    "    for sentence in blob.sentences:\n",
    "        #the sentenceCounter and totalSentiment will be used to average the sentiment score between \n",
    "        #all the sentences\n",
    "        sentenceCounter = sentenceCounter + 1\n",
    "        totalSentiment = totalSentiment + sentence.sentiment.polarity\n",
    "        \n",
    "    averageScore = totalSentiment / sentenceCounter\n",
    "    #displaying results of the review \n",
    "    #print('Total Sentences:', sentenceCounter, 'Total Sentiment Score', totalSentiment,)\n",
    "    #print('Average Score:', averageScore)\n",
    "\n",
    "\n",
    "    #returns the average score rounded to 3 decimal places   \n",
    "    return round(averageScore,3)\n",
    "\n",
    "\n",
    "#assigning the actual reviews (third column) into a separate variable\n",
    "movie_reviews = df[2]\n",
    "\n",
    "#creating arrays to store the scores and labels for each review\n",
    "sentimentScores =[]\n",
    "sentimentLabels = []\n",
    "\n",
    "\n",
    "#looping the reviews and for each one, execute the sentimentAnalysis function and create labels for each review\n",
    "#finally store both scores and labels into the respective arrays, these will be appended to the dataframe\n",
    "for index, review_text in enumerate(movie_reviews):\n",
    "    score = sentimentAnalysis(review_text)\n",
    "    try:\n",
    "        if score > 0.1:\n",
    "            sentimentLabels.append('Positive')\n",
    "        else:\n",
    "            sentimentLabels.append('Negative')\n",
    "    except:\n",
    "        sentimentLabels.append('None')\n",
    "            \n",
    "    sentimentScores.append(score)\n",
    "    \n",
    "#After all the reviews have been classified we can append the sentiment Labels and scores into the df\n",
    "df['Sentiment_Scores'] = sentimentScores\n",
    "df['Sentiment_Classification_Labels'] = sentimentLabels\n",
    "\n",
    "#getting the positive reviews and storing them in a separate variable\n",
    "positiveReviews = df[df.Sentiment_Classification_Labels == 'Positive']\n",
    "negativeReviews = df[df.Sentiment_Classification_Labels == 'Negative']\n",
    "\n",
    "#getting only the reviews column\n",
    "positiveReviewsText = positiveReviews[2].to_string()\n",
    "negativeReviewsText = negativeReviews[2].to_string()\n",
    "\n",
    "#tokenising the text and filtering out punctuation\n",
    "positiveReviewsWords = [word for word in word_tokenize(positiveReviewsText) if word.isalpha()]\n",
    "negativeReviewsWords = [word for word in word_tokenize(negativeReviewsText) if word.isalpha()]\n",
    "\n",
    "#pos tagging the reviews text\n",
    "pos_positiveReviewsWords = pos_tag(positiveReviewsWords)\n",
    "pos_negativeReviewWords = pos_tag(negativeReviewsWords)\n",
    "\n",
    "#getting the bigrams for positive and negative reviews\n",
    "positiveBigrams = list(bigrams(pos_positiveReviewsWords))\n",
    "negativeBigrams = list(bigrams(pos_negativeReviewWords))\n",
    "\n",
    "#function that calculates the frequency of the bigrams\n",
    "def calculate_bigrams_frequency(tagged_bigrams):\n",
    "    bigrams_with_frequencies = {}\n",
    "    for first_element, second_element in tagged_bigrams:\n",
    "        first_word_of_bigram, first_word_pos_tag = first_element[0], first_element[1]\n",
    "        second_word_of_bigram, second_word_pos_tag = second_element[0], second_element[1]\n",
    "        if(first_word_of_bigram, second_word_of_bigram) in bigrams_with_frequencies:\n",
    "            bigrams_with_frequencies[(first_word_of_bigram, second_word_of_bigram)] += 1\n",
    "        else:\n",
    "            bigrams_with_frequencies [(first_word_of_bigram, second_word_of_bigram)] = 1\n",
    "    return bigrams_with_frequencies\n",
    "\n",
    "#calculating frequency of bigrams for both positive and negative reviews\n",
    "positive_bigrams_with_frequencies = calculate_bigrams_frequency(positiveBigrams)\n",
    "negative_bigrams_with_frequencies = calculate_bigrams_frequency(negativeBigrams)\n",
    "\n",
    "\n",
    "#sorting frequencies by descending order\n",
    "positive_bigrams_with_frequencies_sorted = dict(sorted(positive_bigrams_with_frequencies.items(),\n",
    "                                                      key=operator.itemgetter(1), reverse=True))\n",
    "negative_bigrams_with_frequencies_sorted = dict(sorted(negative_bigrams_with_frequencies.items(),\n",
    "                                                      key=operator.itemgetter(1), reverse=True))\n",
    "\n",
    "#Getting the 40 most frequent bigrams for positive reviews\n",
    "counter = 0\n",
    "print('Positive Reviews Bigrams - Sorted By Frequency With No POS Filtering')\n",
    "for bigram in positive_bigrams_with_frequencies_sorted:\n",
    "    print(bigram, positive_bigrams_with_frequencies_sorted[bigram])\n",
    "    counter += 1\n",
    "    if(counter == 40): \n",
    "        break\n",
    "#Getting the 40 most frequent bigrams for negative reviews\n",
    "counter = 0   \n",
    "print('Negative Reviews Bigrams - Sorted By Frequency With No POS Filtering')\n",
    "for bigram in negative_bigrams_with_frequencies_sorted:\n",
    "    print(bigram, negative_bigrams_with_frequencies_sorted[bigram])\n",
    "    counter += 1\n",
    "    if(counter == 40): \n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Reviews Bigrams - Sorted By Frequency With POS Filtering\n",
      "('Mel', 'Brooks') 34\n",
      "('Mel', 'Gibson') 34\n",
      "('great', 'movie') 33\n",
      "('Das', 'Boot') 28\n",
      "('very', 'good') 25\n",
      "('good', 'movie') 25\n",
      "('Close', 'Encounters') 22\n",
      "('Upstairs', 'Downstairs') 20\n",
      "('Henry', 'Winkler') 19\n",
      "('so', 'much') 18\n",
      "('Jane', 'Eyre') 17\n",
      "('first', 'time') 16\n",
      "('Dario', 'Argento') 16\n",
      "('Woody', 'Allen') 14\n",
      "('Downton', 'Abbey') 14\n",
      "('many', 'years') 14\n",
      "('excellent', 'movie') 14\n",
      "('so', 'many') 13\n",
      "('year', 'old') 12\n",
      "('Great', 'movie') 12\n",
      "('classic', 'movie') 12\n",
      "('as', 'good') 11\n",
      "('THIS', 'MOVIE') 11\n",
      "('Third', 'Kind') 11\n",
      "('My', 'husband') 11\n",
      "('first', 'movie') 10\n",
      "('years', 'old') 10\n",
      "('Ben', 'Carson') 10\n",
      "('Steven', 'Spielberg') 9\n",
      "('great', 'film') 9\n",
      "('Home', 'Alone') 9\n",
      "('great', 'story') 9\n",
      "('submarine', 'movie') 8\n",
      "('very', 'interesting') 8\n",
      "('big', 'fan') 7\n",
      "('Bottom', 'Line') 7\n",
      "('true', 'story') 7\n",
      "('A', 'E') 7\n",
      "('last', 'night') 7\n",
      "('original', 'series') 7\n",
      "Negative Reviews Bigrams - Sorted By Frequency With POS Filtering\n",
      "('Mel', 'Gibson') 37\n",
      "('first', 'time') 12\n",
      "('so', 'many') 11\n",
      "('Das', 'Boot') 11\n",
      "('so', 'bad') 11\n",
      "('Elm', 'Street') 11\n",
      "('great', 'movie') 11\n",
      "('Resident', 'Evil') 11\n",
      "('Bottom', 'Line') 10\n",
      "('Mel', 'Brooks') 10\n",
      "('so', 'much') 10\n",
      "('big', 'fan') 10\n",
      "('Texas', 'Chainsaw') 9\n",
      "('THIS', 'MOVIE') 9\n",
      "('movie', 'i') 8\n",
      "('Chainsaw', 'Massacre') 8\n",
      "('not', 'sure') 8\n",
      "('Dario', 'Argento') 8\n",
      "('other', 'reviewers') 8\n",
      "('year', 'old') 7\n",
      "('Jane', 'Eyre') 7\n",
      "('only', 'reason') 7\n",
      "('funny', 'moments') 7\n",
      "('first', 'movie') 7\n",
      "('science', 'fiction') 6\n",
      "('only', 'thing') 6\n",
      "('Adam', 'Sandler') 6\n",
      "('high', 'hopes') 6\n",
      "('bad', 'movie') 6\n",
      "('not', 'much') 6\n",
      "('last', 'night') 6\n",
      "('other', 'reviews') 6\n",
      "('few', 'years') 6\n",
      "('Jurassic', 'Park') 6\n",
      "('Line', 'A') 5\n",
      "('Alyssa', 'Milano') 5\n",
      "('Jennifer', 'Love') 5\n",
      "('Urban', 'Legend') 5\n",
      "('A', 'Nightmare') 5\n",
      "('Gibson', 'Passion') 5\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk import bigrams\n",
    "from nltk import pos_tag\n",
    "import pandas as pd\n",
    "import operator\n",
    "\n",
    "#importing textblob\n",
    "from textblob import TextBlob\n",
    "\n",
    "#specify delimited of csv filed to be the tab character - '\\t\\'\n",
    "#csv file contains no headers so set header = None\n",
    "df = pd.read_csv('Movie_reviews.csv', delimiter = '\\t', header = None)\n",
    "\n",
    "#Creating the sentiment analysis function which returns a sentiment Classification label(1 = positive 0 = negative)\n",
    "def sentimentAnalysis(text):\n",
    "    #calling textblob for the current review\n",
    "    #using exception handler to catch exceptions where the review is not in the proper format\n",
    "    try:\n",
    "        blob = TextBlob(text)\n",
    "    except:\n",
    "        None\n",
    "        return\n",
    "    \n",
    "    sentenceCounter = 0\n",
    "    totalSentiment = 0\n",
    "\n",
    "    #for each review, iterate through the sentences and get the sentiment score of each one\n",
    "    for sentence in blob.sentences:\n",
    "        #the sentenceCounter and totalSentiment will be used to average the sentiment score between \n",
    "        #all the sentences\n",
    "        sentenceCounter = sentenceCounter + 1\n",
    "        totalSentiment = totalSentiment + sentence.sentiment.polarity\n",
    "        \n",
    "    averageScore = totalSentiment / sentenceCounter\n",
    "    #displaying results of the review \n",
    "    #print('Total Sentences:', sentenceCounter, 'Total Sentiment Score', totalSentiment,)\n",
    "    #print('Average Score:', averageScore)\n",
    "\n",
    "\n",
    "    #returns the average score rounded to 3 decimal places   \n",
    "    return round(averageScore,3)\n",
    "\n",
    "\n",
    "#assigning the actual reviews (third column) into a separate variable\n",
    "movie_reviews = df[2]\n",
    "\n",
    "#creating arrays to store the scores and labels for each review\n",
    "sentimentScores =[]\n",
    "sentimentLabels = []\n",
    "\n",
    "\n",
    "#looping the reviews and for each one, execute the sentimentAnalysis function and create labels for each review\n",
    "#finally store both scores and labels into the respective arrays, these will be appended to the dataframe\n",
    "for index, review_text in enumerate(movie_reviews):\n",
    "    score = sentimentAnalysis(review_text)\n",
    "    try:\n",
    "        if score > 0.1:\n",
    "            sentimentLabels.append('Positive')\n",
    "        else:\n",
    "            sentimentLabels.append('Negative')\n",
    "    except:\n",
    "        sentimentLabels.append('None')\n",
    "            \n",
    "    sentimentScores.append(score)\n",
    "    \n",
    "#After all the reviews have been classified we can append the sentiment Labels and scores into the df\n",
    "df['Sentiment_Scores'] = sentimentScores\n",
    "df['Sentiment_Classification_Labels'] = sentimentLabels\n",
    "\n",
    "#getting the positive reviews and storing them in a separate variable\n",
    "positiveReviews = df[df.Sentiment_Classification_Labels == 'Positive']\n",
    "negativeReviews = df[df.Sentiment_Classification_Labels == 'Negative']\n",
    "\n",
    "#getting only the reviews column\n",
    "positiveReviewsText = positiveReviews[2].to_string()\n",
    "negativeReviewsText = negativeReviews[2].to_string()\n",
    "\n",
    "#tokenising the text and filtering out punctuation\n",
    "positiveReviewsWords = [word for word in word_tokenize(positiveReviewsText) if word.isalpha()]\n",
    "negativeReviewsWords = [word for word in word_tokenize(negativeReviewsText) if word.isalpha()]\n",
    "\n",
    "#pos tagging the reviews text\n",
    "pos_positiveReviewsWords = pos_tag(positiveReviewsWords)\n",
    "pos_negativeReviewWords = pos_tag(negativeReviewsWords)\n",
    "\n",
    "#getting the bigrams for positive and negative reviews\n",
    "positiveBigrams = list(bigrams(pos_positiveReviewsWords))\n",
    "negativeBigrams = list(bigrams(pos_negativeReviewWords))\n",
    "\n",
    "#function that calculates the frequency of the bigrams\n",
    "def calculate_bigrams_frequency(tagged_bigrams):\n",
    "    bigrams_with_frequencies = {}\n",
    "    for first_element, second_element in tagged_bigrams:\n",
    "        first_word_of_bigram, first_word_pos_tag = first_element[0], first_element[1]\n",
    "        second_word_of_bigram, second_word_pos_tag = second_element[0], second_element[1]\n",
    "        if(first_word_pos_tag == 'JJ' and second_word_pos_tag == 'NN' or \n",
    "           first_word_pos_tag == 'NN' and second_word_pos_tag == 'NN'\n",
    "          or first_word_pos_tag == 'NNP' and second_word_pos_tag == 'NNP' or \n",
    "           first_word_pos_tag == 'NNP' and second_word_pos_tag == 'NN'\n",
    "          or first_word_pos_tag == 'JJ' and second_word_pos_tag == 'JJ' or \n",
    "           first_word_pos_tag == 'JJ' and second_word_pos_tag == 'NNS'\n",
    "          or first_word_pos_tag == 'NN' and second_word_pos_tag == 'JJ' or \n",
    "           first_word_pos_tag == 'NNS' and second_word_pos_tag == 'JJ'\n",
    "          or first_word_pos_tag == 'RB' and second_word_pos_tag == 'JJ' or \n",
    "           first_word_pos_tag == 'RBS' and second_word_pos_tag == 'JJ'\n",
    "          or first_word_pos_tag == 'RBR' and second_word_pos_tag == 'JJ'):\n",
    "            if(first_word_of_bigram, second_word_of_bigram) in bigrams_with_frequencies:\n",
    "                bigrams_with_frequencies[(first_word_of_bigram, second_word_of_bigram)] += 1\n",
    "            else:\n",
    "                bigrams_with_frequencies [(first_word_of_bigram, second_word_of_bigram)] = 1\n",
    "    return bigrams_with_frequencies\n",
    "\n",
    "#calculating frequency of bigrams for both positive and negative reviews\n",
    "positive_bigrams_with_frequencies = calculate_bigrams_frequency(positiveBigrams)\n",
    "negative_bigrams_with_frequencies = calculate_bigrams_frequency(negativeBigrams)\n",
    "\n",
    "\n",
    "#sorting frequencies by descending order\n",
    "positive_bigrams_with_frequencies_sorted = dict(sorted(positive_bigrams_with_frequencies.items(),\n",
    "                                                      key=operator.itemgetter(1), reverse=True))\n",
    "negative_bigrams_with_frequencies_sorted = dict(sorted(negative_bigrams_with_frequencies.items(),\n",
    "                                                      key=operator.itemgetter(1), reverse=True))\n",
    "\n",
    "#Getting the 40 most frequent bigrams for positive reviews\n",
    "counter = 0\n",
    "print('Positive Reviews Bigrams - Sorted By Frequency With POS Filtering')\n",
    "for bigram in positive_bigrams_with_frequencies_sorted:\n",
    "    print(bigram, positive_bigrams_with_frequencies_sorted[bigram])\n",
    "    counter += 1\n",
    "    if(counter == 40): \n",
    "        break\n",
    "#Getting the 40 most frequent bigrams for negative reviews\n",
    "counter = 0   \n",
    "print('Negative Reviews Bigrams - Sorted By Frequency With POS Filtering')\n",
    "for bigram in negative_bigrams_with_frequencies_sorted:\n",
    "    print(bigram, negative_bigrams_with_frequencies_sorted[bigram])\n",
    "    counter += 1\n",
    "    if(counter == 40): \n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
